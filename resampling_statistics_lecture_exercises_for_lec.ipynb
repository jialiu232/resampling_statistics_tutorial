{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "- [<font color='grey'>Pre-Section 1. What is hacker statistics</font>](#pre-sectionA)\n",
    "\n",
    "- [<font color='grey'>Pre-Section 2. Why hacker statistics?</font>](#pre-section2)\n",
    "\n",
    "- [Section 1. Statistical inference with hacker statistics](#section1)\n",
    "    - [1.1. Bootstrap confidence interval](#1-1)\n",
    "    \n",
    "    - [1.2. Hypothesis test](#1-2)\n",
    "    \n",
    "        - [<font color='grey'>1.2.1. Data pre-processing</font>](#1-2-1)\n",
    "    \n",
    "        - [1.2.2. Permutation test](#1-2-2)\n",
    "    \n",
    "        - [1.2.3. Bonus: Bootstrap hypothesis test](#1-2-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Section 1. What is hacker statistics <a name=\"pre-sectionA\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import dc_stat_think as dcst\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin tossing example  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "np.random.seed(4)\n",
    "\n",
    "# flip one coin\n",
    "random_number = np.random.random(size = 1)\n",
    "random_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the coin flip is a head or tail \n",
    "head = random_number < 0.5\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flipping the coin 10000 times with a for loop and check the probability of heads\n",
    "num_heads = 0 # Initialize the number of heads to be zero\n",
    "for _ in range(10000):\n",
    "    head = np.random.random(size = 1) < 0.5\n",
    "    if head == True:\n",
    "        num_heads += 1\n",
    "num_heads/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed of Light example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the light speed dataa\n",
    "df = pd.read_csv(\"../data/light_speed.csv\", names = [\"speed\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 100 light speed measurements into a numpy array `light_speed`\n",
    "light_speed = np.array(df['speed'])\n",
    "light_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"square root rule\" is a commonly-used rule of thumb for choosing number of bins: \n",
    "# choose the number of bins to be the square root of the number of samples. \n",
    "n_bins = int(np.sqrt(len(light_speed)))\n",
    "print(n_bins)\n",
    "\n",
    "_ = plt.hist(light_speed, bins = n_bins)\n",
    "_ = plt.axvline(x=np.mean(light_speed), color='r', linestyle='-', alpha = 1)\n",
    "_ = plt.xlabel('Speed of light')\n",
    "_ = plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_speed = np.mean(light_speed)\n",
    "print(mean_speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can the mean and median of this 100 measurements represent the real light speed? What is we repeat the experiment again, will the mean or median speed be the same? What if again? again, and again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    bs_sample = np.random.choice(light_speed, size = len(light_speed))\n",
    "    bs_mean = np.mean(bs_sample)\n",
    "    _ = plt.hist(bs_sample, alpha = 0.2, color = 'grey')\n",
    "    _ = plt.axvline(x=bs_mean, color='r', linestyle='-', alpha = 0.2)\n",
    "_ = plt.xlabel('Speed of light')\n",
    "_ = plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often times it is hard for us to repeat an experiment endless of times, and get the \"true\" statistics of a popultation. Here is where hacker statistics can become handy. \n",
    "\n",
    "**Hacker statistics** is using simulated repeated measurements to gather more info about data. The basic idea is that instead of literally repeating the data acquisition over and over again, we can simulate those repeated measurements through **resampling from the original dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Section 2. Why hacker statistics? <a name=\"pre-section2\"></a>\n",
    "\n",
    "Pros: \n",
    "\n",
    "- Resampling based methods do not require the population of interest to be normally distributed\n",
    "\n",
    "- Can be applied to complex estimators\n",
    "\n",
    "- Easy to understand and implement\n",
    "\n",
    "\n",
    "Cons: \n",
    "\n",
    "- All the resampled samples are drawn from the initially observed sample. Thus the observed sample should be randomly drawn from the population\n",
    "\n",
    "- Can be computationally expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Statistical inference with hacker statistics <a name=\"section1\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Bootstrap confidence interval <a name=\"1-1\"></a>\n",
    "\n",
    "Note: The 100 light speed measurements from Michelson's experiment are saved in `light_speed` variable as a numpy array.\n",
    "\n",
    "\n",
    "**1. Create a bootstrap sample for Michelson's light speed data, and compute a bootstrap replicate for a given statistic:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "bs_sample = np.random.choice(light_speed, size = len(light_speed), replace = True)\n",
    "print(bs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(bs_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know \n",
    "\n",
    "- how to draw a bootstrap sample from a given one dimensional sample array using `np.random.choice`, \n",
    "\n",
    "- and how to compute the bootstrap replicate of the bootstrap sample that we are interested in with some functions in `numpy` package, such as `np.mean`. \n",
    "\n",
    "To better maintain the code for future usage, we can summarize the steps above and generate a **function** that **takes** 1) the original one dimensional sample array and 2) function name to compute bootstrap replicate, and **returns** the bootstrap replicate being calculated. Let's do it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn: \n",
    "\n",
    "- **Exercise 1.1.1.** Write a function to draw one bootstrap replicate from a given one dimensional sample array with 2 inputs: sample data, function to calculate the bootstrap replicate.\n",
    "\n",
    "\n",
    "*Instructions*:  \n",
    "\n",
    "1. Use `np.random.choice` function to generate a bootstrap sample from given `data` array. Define this bootstrap sample to have the same length with that of the given `data` array using `size` parameter.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to generate one bootstrap replicate with given 1-d sample and statistic\n",
    "def bs_replicate_1d(data, func):\n",
    "    bs_sample = ____.____.____(____, size = len(data))\n",
    "    return func(bs_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Exercise 1.1.2.** Use the `bs_replicate_1d` function you just wrote to calculate median for a Bootstrap sample generated from Michelson's `light_speed` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_replicate_1d(____, ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Calculate bootstrap confidence interval**\n",
    "\n",
    "**A \"p percent (p$\\%$) Bootstrap confidence interval\" is**: If we resampled the data over and over again, p percent of the observed values would lie within the p percent confidence interval. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to repeat the resample process of the original sample (e.g., `light_speed`) over and over and over again, say 10000 times? For each resampled sample, we want to calculate a summary statistic / Bootstrap replicate (e.g., `np.mean`). A for loop seems to be a good option here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array of length 10000 \n",
    "bs_replicates = np.empty(10000)\n",
    "\n",
    "# Resample the `light_speed` data 10000 times and calculate a Bootstrap replicate each time, \n",
    "# and save each bootstrap replicate to `bs_replicates` array\n",
    "for i in range(10000):\n",
    "    bs_replicates[i] = bs_replicate_1d(light_speed, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bs_replicates` now is an array contains 10000 means calculated from 10000 resampled samples of `light_speed` array. Normally, we may want to know what is the range that most of the replicates locate in? A **confidence interval** can tell you that! Let's see how to use `np.percentile` function to get the $95\\%$ confidence interval of the `bs_replicates` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confidence interval of the mean light speed\n",
    "conf_95 = np.percentile(bs_replicates, [2.5, 97.5])\n",
    "print(conf_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(bs_replicates, density = True, bins = 100)\n",
    "_ = plt.xlabel('mean of light speed')\n",
    "_ = plt.ylabel('counts')\n",
    "plt.ticklabel_format(useOffset=False)\n",
    "_ = plt.axvline(x=conf_95[0], color='r', linestyle='-', alpha = 0.5)\n",
    "_ = plt.axvline(x=conf_95[1], color='r', linestyle='-', alpha = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know how to:\n",
    "\n",
    "- generate a big number (10000) of bootstrap samples from a given data array, \n",
    "- calculate the bootstrap replicate of interest from each of these resampled samples, \n",
    "- and get the confidence interval of the repeated bootstrap replicates. \n",
    "\n",
    "Amazing! Now we will write a function that summarizes the first two steps listed above. With a given sample array (e.g., `light_speed`), a funciton to calculate the bootstrap replicate of interest (e.g., `np.mean`), and the number of times to resample (e.g., `size = 10000`), your function will return an array of bootstrap replicates. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn: \n",
    "\n",
    "- **Exercise 1.1.3.** Write a function to draw bootstrap replicates with 3 inputs: sample data, function to calculate statistic, number of replicates: Now you'll write a function, `draw_bs_reps(data, func, size=1)`, which generates many bootstrap replicates from the given dataset. This function will come in handy for you as you compute Bootstrap confidence intervals in the later sections.\n",
    "\n",
    "\n",
    "\n",
    "*Instructions*:  \n",
    "\n",
    "1. Initialize an empty array of length of given `size` using `np.empty()` function, and save it to `bs_replicates` array. \n",
    "\n",
    "\n",
    "2. Start a for loop with given range (`size`). In each loop, generate a boostrap replicate with input `data` and `func` variables using the `bs_replicate_1d` function you built in the earlier section, and save the replicate to the `i` th position of your `bs_replicates` array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to draw bootstrap replicates with 3 inputs: sample data, function to calculate statistic, number of replicates\n",
    "def draw_bs_reps(data, func, size = 1):\n",
    "    \"\"\"Draw Bootstrap replicates\"\"\"\n",
    "    \n",
    "    # Initialize an empty array of for Bootstrap replicates: bs_replicates\n",
    "    bs_replicates = np.empty(____)\n",
    "    \n",
    "    # Generate replicates\n",
    "    for i in range(____):\n",
    "        bs_replicates[i] = bs_replicate_1d(____, ____)\n",
    "        \n",
    "    return(bs_replicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Exercise 1.1.4.** Use the `draw_bs_reps` function you just created to generate an array of medians (`np.median`) as bootstrap replicates for `light_speed` data, the repeat time for bootstrap is `10000` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = draw_bs_reps(____, ____, size = 10000)\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 95% confidence interval for bs sample \n",
    "np.percentile(bs, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation** of this $95\\%$ Bootstrap confidence interval: If we resampled the data over and over again, $95\\%$ of the observed values would lie within the $95\\%$ confidence interval, which is $[____, ____]$ (as calculated above). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Hypothesis test <a name=\"1-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Read in data & Data pre-processing<a name=\"1-2-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the Oklahoma earthquake data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/oklahoma_earthquakes_1950-2017.csv', skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the time data and visualize the data with a magnitude vs time plot\n",
    "\n",
    "Process the time data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import time\n",
    "# Resource: https://stackoverflow.com/questions/6451655/how-to-convert-python-datetime-dates-to-decimal-float-years\n",
    "\n",
    "def toYearFraction(date):\n",
    "    def sinceEpoch(date): # returns seconds since epoch\n",
    "        return time.mktime(date.timetuple())\n",
    "    s = sinceEpoch\n",
    "\n",
    "    year = date.year\n",
    "    startOfThisYear = dt(year=year, month=1, day=1)\n",
    "    startOfNextYear = dt(year=year+1, month=1, day=1)\n",
    "\n",
    "    yearElapsed = s(date) - s(startOfThisYear)\n",
    "    yearDuration = s(startOfNextYear) - s(startOfThisYear)\n",
    "    fraction = yearElapsed/yearDuration\n",
    "\n",
    "    return date.year + fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.to_datetime(df['time']).apply(toYearFraction).to_numpy()\n",
    "mags = df['mag'].to_numpy()\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(times, mags, marker = '.', linestyle = 'none', alpha = 0.1)\n",
    "_ = plt.xlabel('Time')\n",
    "_ = plt.ylabel('Magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate two data arrays `mags_pre` and `mags_post` for Permutation test example  \n",
    "\n",
    "Note: \n",
    "\n",
    "- We will focus on the earthquakes that were at least at magnitude of 3  \n",
    "\n",
    "- `mags_pre`: an array contains the earthquake magnitudes before year 2010 ($1980 \\le \\text{year} < 2010$)\n",
    "\n",
    "- `mags_post`: an array contains the earthquake magnitudes after year 2010 ($2010 \\le \\text{year} \\le 2017$)   \n",
    "\n",
    "Generate the two data arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags_pre = mags[(times < 2010) & (times >= 1980)]\n",
    "mags_post = mags[times >= 2010]\n",
    "\n",
    "mt = 3  # Define the magnitudes lowest threshold to study \n",
    "mags_pre = mags_pre[mags_pre >= mt]\n",
    "mags_post = mags_post[mags_post >= mt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic EDA on `mags_pre` and `mags_post`: \n",
    "\n",
    "Mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mags_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mags_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two sample T-test: \n",
    "\n",
    "**NOTE**: I didn't check the assumptions of the t-test here. So the result is NOT trustworthy!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.ttest_ind(mags_pre, mags_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap confidence interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_mags_pre = draw_bs_reps(mags_pre, np.mean, size = 10000)\n",
    "bs_mags_post = draw_bs_reps(mags_post, np.mean, size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(bs_mags_pre, [2.5, 97.5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(bs_mags_post, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate two data arrays `dt_pre` and `dt_post` for Bootstrap test example \n",
    "\n",
    "Note: \n",
    "\n",
    "- We will focus on the earthquakes that were at least at magnitude of 3  \n",
    "\n",
    "- `dt_pre`: an array contains the earthquake frequencies before year 2010 ($1980 \\le \\text{year} < 2010$)\n",
    "\n",
    "- `dt_post`: an array contains the earthquake frequencies after year 2010 ($2010 \\le \\text{year} \\le 2017$)  \n",
    "\n",
    "Generate the two arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_over3 = df[df['mag'] >= 3]\n",
    "df_over3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_over3['time'] = pd.to_datetime(df_over3['time']).copy()\n",
    "#df_over3['time'] = pd.to_datetime(df_over3['time'])\n",
    "df_over3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pre_df = df_over3[(df_over3['time'].dt.year < 2010) & (df_over3['time'].dt.year >= 1980)]\n",
    "dt_post_df = df_over3[df_over3['time'].dt.year >= 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pre = dt_pre_df.time.diff().dt.total_seconds().apply(lambda x: x / 86400).to_numpy()[1:]\n",
    "dt_post = dt_post_df.time.diff().dt.total_seconds().apply(lambda x: x / 86400).to_numpy()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic EDA for the two earthquake frequency arrays: \n",
    "\n",
    "Mean: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pre_mean = np.mean(dt_pre)\n",
    "dt_pre_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_post_mean = np.mean(dt_post)\n",
    "dt_post_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap Confidence interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_dt_pre = draw_bs_reps(dt_pre, np.mean, size = 10000)\n",
    "bs_dt_post = draw_bs_reps(dt_post, np.mean, size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(bs_dt_pre, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(bs_dt_post, [2.5, 97.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Permutation test <a name=\"1-2-2\"></a>\n",
    "\n",
    "In this section, you will learn how to use permutation test on the magnitudes of earthquakes before and after 2010\n",
    "\n",
    "**Note**: \n",
    "\n",
    "- The null hypothesis of permutation test assumes that the two populations being compared have **the same distribution**\n",
    "\n",
    "- the earthquake magnitudes data before and after year 2010 are saved in `mags_pre` and `mags_post` arrays separately, and ready for you to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Generate a pair of permutation sample from `mags_pre` and `mags_post` data and calculate a test statistic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate `mags_pre` and `mags_post` array into one big array\n",
    "combined_mags = np.concatenate((mags_pre, mags_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly reorder the concatenated array\n",
    "permuted_mags = np.random.permutation(combined_mags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract permutation samples\n",
    "perm_mags_pre = permuted_mags[:len(mags_pre)]\n",
    "perm_mags_post = permuted_mags[len(mags_pre):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference of mean magnitudes calculated from permutation sample\n",
    "diff_perm = np.mean(perm_mags_post) - np.mean(perm_mags_pre)\n",
    "diff_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know how to: \n",
    "\n",
    "- concatenate two sample arrays you want to compare with `np.concatenate` function\n",
    "\n",
    "- randomly permute / reorder an array with `np.random.permutation` function\n",
    "\n",
    "- extract a pair of permutation sample from the permuted array above\n",
    "\n",
    "- calculate test statistic from the permutation sample   \n",
    "\n",
    "\n",
    "It's time to create a function that summarizes the first three steps listed above and generates a pair of permutation sample based on two given input one-dimensional arrays. Let's do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "\n",
    "- **Exercise 1.2.2.1.** Write a function `permutation_sample()` that takes two input arrays, concatenates, permutes, and returns two permuted arrays. \n",
    "\n",
    "*Instruction*:\n",
    "\n",
    "1. Use `np.concatenate` function to concatenate the two input arrays\n",
    "\n",
    "2. Permute the concatenated array with `np.random.permutation` function\n",
    "\n",
    "3. Split the permuted array into two: \n",
    "\n",
    "    - 1. the first array `perm_out_1` contains the first \"$n = \\text{length of first input array}$\" entries in the permuted array\n",
    "    \n",
    "    - 2. the second array `perm_out_2` contains the rest of the entries in the permuted array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get permutation sample\n",
    "def permutation_sample(data1, data2):\n",
    "    '''Generate a permutation sample from two input 1-d arrays'''\n",
    "    \n",
    "    # Concatenate the two input datasets into one array\n",
    "    data = ____.____((data1, data2))\n",
    "    \n",
    "    # Permute the concatenated data\n",
    "    permute_data = ____.____.____(____)\n",
    "    \n",
    "    # Split the permuted array into two\n",
    "    perm_out_1 = permute_data[:____]\n",
    "    perm_out_2 = permute_data[len(data1):]\n",
    "    \n",
    "    # Return the two permuted arrays\n",
    "    return(perm_out_1, perm_out_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Exercise 1.2.2.2.** Use the `permutation_sample()` function you just created to generate a pair of permutation sample from `mags_pre` and `mags_post` arrays. \n",
    "\n",
    "\n",
    "*Instruction*:\n",
    "\n",
    "1. Pass the two sample arrays to `permutation_sample()` function, and save the output to `p_pre` and `p_post` variables separately\n",
    "\n",
    "2. Print the size of `p_pre` and `p_post` arrays using `len()` function separately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pre, p_post = permutation_sample(____, ____)\n",
    "print(\"The size of the earthquake magnitudes permutation sample before 2010 is\", len(p_pre))\n",
    "print(\"The size of the earthquake magnitudes permutation sample after 2010 is\", ____(____))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Exercise 1.2.2.3.** Write a function `mean_diff()` that takes two input arrays, and returns the difference of means of these two arrays. \n",
    "\n",
    "*Instruction*:\n",
    "\n",
    "- `np.mean()` function can be used to calculate the means of each array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_diff(arr1, arr2):\n",
    "    diff = ____.____(arr2) - ____.____(arr1)\n",
    "    return(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Exercise 1.2.2.4.** Use the `mean_diff()` function you created in Exercise 1.2.2.3 to calculate the difference of means between `p_pre` and `p_post` arrays you generated in the Exercise 1.2.2.2\n",
    "\n",
    "*Instruction*:\n",
    "\n",
    "- Pass the two arrays (`p_pre`, `p_post`) to `mean_diff()` function, and save the output to variable `p_diff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `mean_diff()` function to calculate the difference between means of \n",
    "# p_pre and p_post arrays you generated in the exercise above\n",
    "p_diff = mean_diff(____, ____)\n",
    "\n",
    "print(p_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Generate a large number of permutation samples and perform permutation test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 10000 permutation samples and calculate test statistic for each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array of length 10000 \n",
    "perm_mag_ts = np.empty(10000)\n",
    "\n",
    "for i in range(10000):\n",
    "    perm_1, perm_2 = permutation_sample(mags_pre, mags_post)\n",
    "    perm_mag_ts[i] = mean_diff(perm_1, perm_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the observed test statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed difference in mean magnitudes: diff_obs\n",
    "diff_obs = np.mean(mags_post) - np.mean(mags_pre)\n",
    "print(diff_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing that the difference of magnitude means before and after 2010 is our test statistic, we got the observed test statistic, and 10000 test statistics calculated from the 10000 simulated permutation samples. We want to know how extreme our observed test statistic is, given the null hypothesis (where all the permutation samples were generated under) is true. \n",
    "\n",
    "Let's plot all the test statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(perm_mag_ts, bins = 100)\n",
    "_ = plt.xlabel('test statistics')\n",
    "_ = plt.ylabel('counts')\n",
    "plt.ticklabel_format(useOffset=False)\n",
    "_ = plt.axvline(x=diff_obs, color='r', linestyle='-', alpha = 0.5)\n",
    "_ = plt.axvline(x=abs(diff_obs), color='r', linestyle='-', alpha = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the p-value for a permutation test, we simply count the number of test-statistics as or more extreme than our initially observed test statistic, and divide that number by the total number of test-statistics we calculated.   \n",
    "\n",
    "Calculate p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(abs(perm_mag_ts) > abs(diff_obs)) / 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a $p-value > 0.05$, we failed to reject the null hypothesis. We do not have enough evidence to conclude that waste water injection in Oklahoma in 2010 changed the earthquake magnitudes happened there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know how to:\n",
    "\n",
    "- generate a large number of permutation samples\n",
    "\n",
    "- calculate a test statistic for each sample\n",
    "\n",
    "- compute p-value for a permutation test\n",
    "\n",
    "Next we will write a function that summarizes the first two steps given above, generates an array of permutation test statistics based on two input arrays, one function to compute test statistic, and the number of permutation resampling to perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You turn  \n",
    "\n",
    "- **Exercise 1.2.2.5.** Write a function `draw_permutation_reps()` that generates permutation samples of given size, calculates test statistics with given function for each sample and returns all the test statistics in an array. \n",
    "\n",
    "*Instruction*:\n",
    "\n",
    "1. Initialize an empty array of given `size` using `np.empty` function\n",
    "\n",
    "2. Within the for loop\n",
    "\n",
    "    - 1. generate a pair of permutation sample from the two input arrays using a function you created above\n",
    "    \n",
    "    - 2. calculate test statistic for the new generated pair of permutation samples, and save the value to the i th entry of `perm_reps` array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to generate permutation statistic replicates\n",
    "def draw_permutation_reps(data1, data2, func, size = 1):\n",
    "    '''Generate permutation statistic replicates of given size'''\n",
    "    \n",
    "    # Initiate an empty permutation array \n",
    "    perm_reps = ____.____(____)\n",
    "    \n",
    "    for i in range(____):\n",
    "        \n",
    "        # Generate a pair of permutation sample with given array\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(____, ____)\n",
    "        \n",
    "        # calculate test statistic using the input func\n",
    "        perm_reps[i] = func(perm_sample_1, perm_sample_2)\n",
    "        \n",
    "    return(perm_reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Exercise 1.2.2.6.** Based on the `mags_pre` and `mags_post` arrays, use the `draw_permutation_reps` function you just created to resample and get `size = 100000` test statistics calculated by `mean_diff` function. (It may take several minutes to run)\n",
    "\n",
    "*Instruction*: \n",
    "\n",
    "1. Pass the 4 arguments in the right order to `draw_permutation_reps` function\n",
    "\n",
    "2. Calculate the observed test statistics, and save the result to `diff_obs` variable\n",
    "\n",
    "3. To calculate the p-value, count the total number of permutation-sample-generated test statistics (`perm_reps`) whose absolute value are as or more extreme as that of the originally observed test statistic (`diff_obs`), and then divide this count by the total number of permutation test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate permutation replicates: perm_reps\n",
    "perm_reps = draw_permutation_reps(____, ____, ____, size=____)\n",
    "\n",
    "# Calculate observed test statistic from `mags_pre` and `mags_post` arrays: diff_obs\n",
    "diff_obs = ...\n",
    "\n",
    "# Compute and print p-value\n",
    "p_val = np.sum(abs(____) > abs(____)) / ____\n",
    "print('p =', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: 1.2.3 Bootstrap hypothesis test <a name=\"1-2-3\"></a>\n",
    "\n",
    "\n",
    "From the permutation test in the last section, we didn't find enough evidence to conclude that injection of waste water in Oklahoma in 2010 caused the change of earthquake magnitides there. But as shown in the figure below, the frequencies of earthquakes since 2010 seems to be changed compared with those before 2010. Thus, in this section, we are interested in comparing the average frequencies of earthquakes before and after year 2010. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(times, mags, marker = '.', linestyle = 'none', alpha = 0.1)\n",
    "_ = plt.xlabel('Time')\n",
    "_ = plt.ylabel('Magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the null hypothesis of permutation test assumes that the two populations being compared have the same distribution, injection of waste water to the ground may have already changed the earthquake frequency distribution after 2010. What if we do not care if the same distribution were followed, but **only want to know if the average earthquake frequencies in Oklahoma before and after year 2010 are the same**? Hypothesis test with Bootstrap will do it here.  \n",
    "\n",
    "In this section, you will learn how to use hypothesis test with Bootstrap on the frequency of earthquakes before and after 2010\n",
    "\n",
    "**Note**: the time gaps between earthquakes before and after year 2010 are saved in `dt_pre` and `dt_post` arrays separately, and ready for you to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence interval for `dt_pre` and `dt_post`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_dt_pre = draw_bs_reps(dt_pre, np.mean, size = 10000)\n",
    "bs_dt_post = draw_bs_reps(dt_post, np.mean, size = 10000)\n",
    "\n",
    "print(\"Bootstrap confidence interval for dt_pre:\", np.percentile(bs_dt_pre, [2.5, 97.5]))\n",
    "print(\"Bootstrap confidence interval for dt_post:\", np.percentile(bs_dt_post, [2.5, 97.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the observed test statistic, which is the difference of dt_pre and dt_post means\n",
    "dt_pre_mean = np.mean(dt_pre)\n",
    "dt_post_mean = np.mean(dt_post)\n",
    "observed_diff = dt_pre_mean - dt_post_mean\n",
    "\n",
    "\n",
    "# Shift the dt_post data under the null hypothesis (so that they have the same means as the dt_pre data)\n",
    "shifed_dt_post = dt_post - np.mean(dt_post) + np.mean(dt_pre)\n",
    "\n",
    "# Generate Bootstrap replicated means for dt_pre and shifted_dt_post\n",
    "bs_dt_pre = draw_bs_reps(dt_pre, np.mean, size = 10000)\n",
    "bs_shifted_dt_post = draw_bs_reps(shifed_dt_post, np.mean, size = 10000)\n",
    "\n",
    "# Calculate the replicated test statistic diff\n",
    "bs_reps_diff = bs_dt_pre - bs_shifted_dt_post\n",
    "\n",
    "\n",
    "# Calculate the p-values\n",
    "p = np.sum(bs_reps_diff >= observed_diff)/len(bs_reps_diff)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p-value = 0$ suggests that if the null hypothesis is true, there is very very few or none simultated test statistics is as or more extreme than the observed one. Thus, the injection of waste water in Oklahoma probably influenced the earthquake frequencies there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**: \n",
    "\n",
    "- This notebook was built mainly based on Dr. Justin Bois's three statistical courses on [Datacamp website](https://www.datacamp.com/instructors/bois)\n",
    "\n",
    "- An interesting tutorial about [permutation test](https://www.jwilber.me/permutationtest/) may help you understand it better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
